{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [雅可比矩阵](https://zh.wikipedia.org/wiki/%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5)\n",
    "$$\n",
    "\\text{给定向量}\n",
    "\\bf{x} = \n",
    "\\begin{bmatrix}\n",
    " x{_1} \\\\ x{_2} \\\\ \\vdots \\\\ x{_n}\n",
    "\\end{bmatrix}\n",
    ",\n",
    "\\bf{y} = \n",
    "\\begin{bmatrix}\n",
    " y{_1} \\\\ y{_2} \\\\ \\vdots \\\\ y{_m}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "设函数f是一个从n维欧式空间映射到m维欧式空间的函数,函数由m个实数组成:\n",
    "$$\n",
    "y{_1}(x{_1},\\cdots,x{_n}),\\cdots,y{_m}(x{_1},\\cdots,x{_n})\n",
    "$$\n",
    "则这些函数的偏导数可以组成一个m x n的矩阵,这个矩阵就是雅可比矩阵\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial{y{_1}}}{\\partial{x{_1}}} & \\cdots & \\frac{\\partial{y{_1}}}{\\partial{x{_n}}} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial{y{_m}}}{\\partial{x{_1}}} & \\cdots & \\frac{\\partial{y{_m}}}{\\partial{x{_n}}} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "# [矩阵求导布局规范](https://en.wikipedia.org/wiki/Matrix_calculus#Layout_conventions)\n",
    "\n",
    "| matrix | vector | scalar |\n",
    "| ------------- | ------------- | ------------- |\n",
    "| $\\bf{X},\\bf{Y}$ | $\\bf{x},\\bf{y}$ | $x,y$ |\n",
    "\n",
    "本质上的问题是:当向量对向量求导时,即$\\frac{\\partial{\\bf{y}}}{\\partial{\\bf{x}}}$,可以写作成两种矛盾的格式.假设$\\bf{y}$是m维列向量,$\\bf{x}$是n维度列向量,则求导结果可以是 n×m matrix 也可以是m×n matrix\n",
    "\n",
    "- Numerator layout: 求导结果根据$\\bf{y}$和$\\bf{x{^T}}$布局,这也就是Jacobian formulation.$\\frac{\\partial{\\bf{y}}}{\\partial{x}}$布局为行向量,$\\frac{\\partial{y}}{\\partial{\\bf{x}}}$布局为列向量\n",
    "\n",
    "- Denominator layout : 也被叫做Hessian formulation,是Jacobian formulation的转置\n",
    "<table class=\"wikitable\">\n",
    "<caption>Result of differentiating various kinds of aggregates with other kinds of aggregates\n",
    "</caption>\n",
    "<tbody><tr>\n",
    "<th colspan=\"2\" rowspan=\"2\">\n",
    "</th>\n",
    "<th colspan=\"2\">Scalar <i>y</i>\n",
    "</th>\n",
    "<th colspan=\"2\">Column vector <b>y</b> (size <i>m</i>×<i>1</i>)\n",
    "</th>\n",
    "<th colspan=\"2\">Matrix <b>Y</b> (size <i>m</i>×<i>n</i>)\n",
    "</th></tr>\n",
    "<tr>\n",
    "<th>Notation</th>\n",
    "<th>Type\n",
    "</th>\n",
    "<th>Notation</th>\n",
    "<th>Type\n",
    "</th>\n",
    "<th>Notation</th>\n",
    "<th>Type\n",
    "</th></tr>\n",
    "<tr>\n",
    "<th rowspan=\"2\">Scalar <i>x</i>\n",
    "</th>\n",
    "<th>Numerator\n",
    "</th>\n",
    "<td rowspan=\"2\" style=\"text-align:center;\"><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle {\\frac {\\partial y}{\\partial x}}}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "          <mfrac>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mi>y</mi>\n",
    "            </mrow>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mi>x</mi>\n",
    "            </mrow>\n",
    "          </mfrac>\n",
    "        </mrow>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\displaystyle {\\frac {\\partial y}{\\partial x}}}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/0deac2b96aa5d0329450647f183f9365584c67b2\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.005ex; width:3.484ex; height:5.676ex;\" alt=\"\\frac{\\partial y}{\\partial x}\"></span>\n",
    "</td>\n",
    "<td rowspan=\"2\">Scalar\n",
    "</td>\n",
    "<td rowspan=\"2\" style=\"text-align:center;\"><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle {\\frac {\\partial \\mathbf {y} }{\\partial x}}}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "          <mfrac>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">y</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mi>x</mi>\n",
    "            </mrow>\n",
    "          </mfrac>\n",
    "        </mrow>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\displaystyle {\\frac {\\partial \\mathbf {y} }{\\partial x}}}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/67d5f2cf89374e95eb31cdf816533244b4d45d1d\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.005ex; width:3.565ex; height:5.676ex;\" alt=\"\\frac{\\partial \\mathbf{y}}{\\partial x}\"></span>\n",
    "</td>\n",
    "<td>Size-<i>m</i> <a href=\"/wiki/Column_vector\" class=\"mw-redirect\" title=\"Column vector\">column vector</a>\n",
    "</td>\n",
    "<td rowspan=\"2\" style=\"text-align:center;\"><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle {\\frac {\\partial \\mathbf {Y} }{\\partial x}}}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "          <mfrac>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">Y</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mi>x</mi>\n",
    "            </mrow>\n",
    "          </mfrac>\n",
    "        </mrow>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\displaystyle {\\frac {\\partial \\mathbf {Y} }{\\partial x}}}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/565884c84274a792e9b5af680a30f550eaf5e3a6\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.005ex; width:4.174ex; height:5.509ex;\" alt=\"\\frac{\\partial \\mathbf{Y}}{\\partial x}\"></span>\n",
    "</td>\n",
    "<td><i>m</i>×<i>n</i> matrix\n",
    "</td></tr>\n",
    "<tr>\n",
    "<th>Denominator\n",
    "</th>\n",
    "<td>Size-<i>m</i> <a href=\"/wiki/Row_vector\" class=\"mw-redirect\" title=\"Row vector\">row vector</a>\n",
    "</td>\n",
    "<td>\n",
    "</td></tr>\n",
    "<tr>\n",
    "<th rowspan=\"2\">Column vector <b>x</b><br>(size <i>n</i>×<i>1</i>)\n",
    "</th>\n",
    "<th>Numerator\n",
    "</th>\n",
    "<td rowspan=\"2\" style=\"text-align:center;\"><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle {\\frac {\\partial y}{\\partial \\mathbf {x} }}}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "          <mfrac>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mi>y</mi>\n",
    "            </mrow>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">x</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "          </mfrac>\n",
    "        </mrow>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\displaystyle {\\frac {\\partial y}{\\partial \\mathbf {x} }}}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/01a7fae63303065a57b24c2bb67ab80468a24263\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.005ex; width:3.565ex; height:5.676ex;\" alt=\"\\frac{\\partial y}{\\partial \\mathbf{x}}\"></span>\n",
    "</td>\n",
    "<td>Size-<i>n</i> <a href=\"/wiki/Row_vector\" class=\"mw-redirect\" title=\"Row vector\">row vector</a>\n",
    "</td>\n",
    "<td rowspan=\"2\" style=\"text-align:center;\"><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle {\\frac {\\partial \\mathbf {y} }{\\partial \\mathbf {x} }}}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "          <mfrac>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">y</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">x</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "          </mfrac>\n",
    "        </mrow>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\displaystyle {\\frac {\\partial \\mathbf {y} }{\\partial \\mathbf {x} }}}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/734fea892fc38deec1d53fa88abed4ca213c0d25\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.005ex; width:3.565ex; height:5.676ex;\" alt=\"\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}}\"></span>\n",
    "</td>\n",
    "<td><i>m</i>×<i>n</i> matrix\n",
    "</td>\n",
    "<td rowspan=\"2\" style=\"text-align:center;\"><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle {\\frac {\\partial \\mathbf {Y} }{\\partial \\mathbf {x} }}}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "          <mfrac>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">Y</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">x</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "          </mfrac>\n",
    "        </mrow>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\displaystyle {\\frac {\\partial \\mathbf {Y} }{\\partial \\mathbf {x} }}}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/433f2d2da465f5a3f2aa8dff5c9d6dd8e9947eef\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.005ex; width:4.174ex; height:5.509ex;\" alt=\"\\frac{\\partial \\mathbf{Y}}{\\partial \\mathbf{x}}\"></span>\n",
    "</td>\n",
    "<td rowspan=\"2\">\n",
    "</td></tr>\n",
    "<tr>\n",
    "<th>Denominator\n",
    "</th>\n",
    "<td>Size-<i>n</i> <a href=\"/wiki/Column_vector\" class=\"mw-redirect\" title=\"Column vector\">column vector</a>\n",
    "</td>\n",
    "<td><i>n</i>×<i>m</i> matrix\n",
    "</td></tr>\n",
    "<tr>\n",
    "<th rowspan=\"2\">Matrix <b>X</b><br>(size <i>p</i>×<i>q</i>)\n",
    "</th>\n",
    "<th>Numerator\n",
    "</th>\n",
    "<td rowspan=\"2\" style=\"text-align:center;\"><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle {\\frac {\\partial y}{\\partial \\mathbf {X} }}}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "          <mfrac>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mi>y</mi>\n",
    "            </mrow>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">X</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "          </mfrac>\n",
    "        </mrow>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\displaystyle {\\frac {\\partial y}{\\partial \\mathbf {X} }}}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/877eb58a8159dedbc4bc47afc9749803d75d5e35\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.005ex; width:4.174ex; height:5.676ex;\" alt=\"\\frac{\\partial y}{\\partial \\mathbf{X}}\"></span>\n",
    "</td>\n",
    "<td><i>q</i>×<i>p</i> matrix\n",
    "</td>\n",
    "<td rowspan=\"2\" style=\"text-align:center;\"><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle {\\frac {\\partial \\mathbf {y} }{\\partial \\mathbf {X} }}}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "          <mfrac>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">y</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">X</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "          </mfrac>\n",
    "        </mrow>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\displaystyle {\\frac {\\partial \\mathbf {y} }{\\partial \\mathbf {X} }}}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/86a7d5bedcc1bc202bd55040b26137a6c1740850\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.005ex; width:4.174ex; height:5.676ex;\" alt=\"\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{X}}\"></span>\n",
    "</td>\n",
    "<td rowspan=\"2\">\n",
    "</td>\n",
    "<td rowspan=\"2\" style=\"text-align:center;\"><span class=\"mwe-math-element\"><span class=\"mwe-math-mathml-inline mwe-math-mathml-a11y\" style=\"display: none;\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" alttext=\"{\\displaystyle {\\frac {\\partial \\mathbf {Y} }{\\partial \\mathbf {X} }}}\">\n",
    "  <semantics>\n",
    "    <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "      <mstyle displaystyle=\"true\" scriptlevel=\"0\">\n",
    "        <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "          <mfrac>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">Y</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "            <mrow>\n",
    "              <mi mathvariant=\"normal\">∂<!-- ∂ --></mi>\n",
    "              <mrow class=\"MJX-TeXAtom-ORD\">\n",
    "                <mi mathvariant=\"bold\">X</mi>\n",
    "              </mrow>\n",
    "            </mrow>\n",
    "          </mfrac>\n",
    "        </mrow>\n",
    "      </mstyle>\n",
    "    </mrow>\n",
    "    <annotation encoding=\"application/x-tex\">{\\displaystyle {\\frac {\\partial \\mathbf {Y} }{\\partial \\mathbf {X} }}}</annotation>\n",
    "  </semantics>\n",
    "</math></span><img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/0d7d1744e8920b3885bde9168c70643df3a49cd3\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.005ex; width:4.174ex; height:5.509ex;\" alt=\"\\frac{\\partial \\mathbf{Y}}{\\partial \\mathbf{X}}\"></span>\n",
    "</td>\n",
    "<td rowspan=\"2\">\n",
    "</td></tr>\n",
    "<tr>\n",
    "<th>Denominator\n",
    "</th>\n",
    "<td><i>p</i>×<i>q</i> matrix\n",
    "</td></tr></tbody></table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network\n",
    "\n",
    "## [activation functions](https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html)\n",
    "\n",
    "$$\n",
    "singmod = ...\n",
    "$$\n",
    "\n",
    "$$\n",
    "tanh(x) = \\frac{e{^z}-e{^{-z}}}{e{^z}+e{^{-z}}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{rectified linear unit:   }relu(z) = \n",
    "\\begin{cases} \n",
    "0, & \\text {if $z<0$} \\\\ \n",
    "z, & \\text{if $z>0$} \n",
    "\\end{cases} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{leaking relu}(z) = \n",
    "\\begin{cases} \n",
    "0.0 1z, & \\text {if $z<0$} \\\\ \n",
    "z, & \\text{if $z>0$} \n",
    "\\end{cases} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{softmax: }  \\hat{y_{i}} =p_{i} =  \n",
    "\\frac{e^{z_{i}}}{\\sum_{k=1}^{m}e^{z_{k}}}\n",
    "$$\n",
    "\n",
    "## [loss function](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)\n",
    "\n",
    "$$\n",
    "\\text{Cross Entropy:  }\n",
    "E = \n",
    "\\begin{cases}\n",
    "-(y\\log{(p)} + (1-y)\\log{(1-p)}) & \n",
    "\\text{binary classification}\\\\\n",
    "-\\sum_{i=1}^{m}y_{i}\\log{(p_{i})} & \n",
    "\\text{multiclass classification,  m is the number of classes }\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of Cross Entropy and Softmax\n",
    "\n",
    "$\n",
    "\\bf{y}\\in{\\bf{R}^{m\\times1}},\n",
    "\\bf{p}\\in{\\bf{R}^{m\\times1}}\n",
    "$\n",
    "对loss function 求导:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{E}}{\\partial{p_{j}}} = \n",
    "\\frac{-\\sum_{i=1}^{m}y_{i}\\log{(p_{i})}}{\\partial{p_{j}}} = \n",
    "\\frac{y_{j}}{p_{j}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{E}}{\\partial{\\bf{P}}} = \n",
    "\\begin{bmatrix}\n",
    "\\frac{y_{1}}{p_{1}}　& \\cdots & \\frac{y_{m}}{p_{m}}\n",
    "\\end{bmatrix}=\n",
    "(\\frac{\\bf{y}}{\\bf{p}})^{T}\n",
    ", \\in{\\bf{R}^{1\\times m}}\n",
    "$$\n",
    "\n",
    "对 activation functions 求导\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{p_{i}}}{\\partial{z_{j}}} = \\frac{\\frac{e^{z_{i}}}{\\sum_{k=1}^{m}e^{z_{k}}}}{z_{j}}\n",
    "= \n",
    "\\begin{cases}\n",
    "p_{i}(1-p_{i})& j=i \\\\\n",
    "p_{i}p_{j}& j\\neq{i}\n",
    "\\end{cases}\n",
    ", \\in{\\bf{R}^{m\\times m}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{P}}{\\partial{\\bf{Z}}} \\in \\bf{R}^{m \\times m}\n",
    "$$\n",
    "\n",
    "综合以上\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\frac{y_{1}}{p_{1}}　& \\cdots & \\frac{y_{m}}{p_{m}}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "p_{1}(1-p_{1}) & p_{1}p_{2} & \\cdots & p_{1}p_{m} \\\\\n",
    "p_{2}p_{1} & p_{2}(1-p_{2}) &  \\cdots & p_{2}p_{m} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "p_{m}p_{1} & p_{m}p_{2} &  \\cdots & p_{m}(1-p_{m}) \\\\ \n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "p_{1}-y_{1} &\n",
    "p_{2}-y_{2} &\n",
    "\\cdots &\n",
    "p_{m}-y_{m}&\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{E}}{\\partial{Z}} = \\frac{\\partial{E}}{\\partial{\\bf{P}}} \\cdot\n",
    "\\frac{\\partial{P}}{\\partial{\\bf{Z}}}\n",
    ",\\in{\\bf{R^{1 \\times m}}}\n",
    "$$\n",
    "\n",
    "若拆开计算,特别注意\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{E}}{\\partial{z_{j}}} = \\sum_{i = 1}^{m}\n",
    "\\frac{\\partial{E}}{\\partial{p_{i}}} \n",
    "\\frac{\\partial{p_{i}}}{\\partial{z_{j}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对于单层神经网络\n",
    "输入层$\\bf{x}\\in{R^{a \\times 1}}$,\n",
    "隐藏层$\\bf{h}\\in{R^{b \\times 1}}$,\n",
    "输出层$\\bf{o}\\in{R^{c \\times 1}}$,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\bf{z}^{[1]} = \\bf{W}^{[1]}\\bf{x} + \\bf{b}^{1} \\\\\n",
    "& \\bf{h} = sigmoid(\\bf{z}^{[1]}) \\\\\n",
    "& \\bf{z}^{[2]} = \\bf{W}^{[2]}\\bf{h} + \\bf{b}^{[2]} \\\\\n",
    "& \\bf{p} = softmax(\\bf{z^{[2]}}) \\\\\n",
    "& \\bf{E} = -\\bf{y}^{T}\\log{(\\bf{p})}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "需要求\n",
    "$\\frac{\\partial{E}}{\\partial{w}^{[1]}}$,\n",
    "$\\frac{\\partial{E}}{\\partial{b}^{[1]}}$,\n",
    "$\\frac{\\partial{E}}{\\partial{h}}$\n",
    "$\\frac{\\partial{E}}{\\partial{w}^{[2]}}$,\n",
    "$\\frac{\\partial{E}}{\\partial{b}^{[2]}}$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\frac{\\partial{E}}{\\partial{\\bf{W}}^{[2]}} = \\frac{\\partial{E}}{\\partial{\\bf{p}}}\n",
    "\\frac{\\partial{\\bf{p}}}{\\partial{\\bf{z}^{[2]}}} \\frac{{\\partial{\\bf{z}^{[2]}}}}{{\\partial{\\bf{W}^{[2]}}}} \\\\\n",
    "& \\frac{{\\partial{\\bf{z}^{[2]}}}}{{\\partial{\\bf{W}^{[2]}}}} = \n",
    "\\begin{bmatrix}\n",
    "\\frac{{\\partial{\\bf{z}^{[2]}_{1}}}}{{\\partial{\\bf{W}^{[2]}}}} \\\\\n",
    "\\frac{{\\partial{\\bf{z}^{[2]}_{2}}}}{{\\partial{\\bf{W}^{[2]}}}} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{{\\partial{\\bf{z}^{[2]}_{c}}}}{{\\partial{\\bf{W}^{[2]}}}}\n",
    "\\end{bmatrix} \\in{R^{c \\times 1}}\\\\\n",
    "&\n",
    "\\frac{{\\partial{\\bf{z}^{[2]}_{i}}}}{{\\partial{{W}_{xy}^{[2]}}}}=\n",
    "\\frac{\\partial{\\sum_{k=1}^{b}w_{ik}h_{k}}}{{\\partial{W_{xy}^{[2]}}}}\\\\\n",
    "& 可知当 x=i,y=j时\\frac{{\\partial{\\bf{z}^{[2]}_{i}}}}{{\\partial{{W}_{xy}^{[2]}}}} = h_{y} \\\\\n",
    "& \\frac{{\\partial{\\bf{z}^{[2]}_{i}}}}{{\\partial{\\bf{W}^{[2]}}}} = \n",
    "\\begin{bmatrix}\n",
    "0&0&\\cdots&0\\\\\n",
    "\\vdots&\\vdots& \\ddots &\\vdots\\\\\n",
    "h_{1} &h_{2} &\\cdots & h_{b}\\\\\n",
    "\\vdots&\\vdots& \\ddots &\\vdots\\\\\n",
    "0&0&\\cdots&0\\\\\n",
    "\\end{bmatrix} \\in{R^{c \\times b}}\\\\\n",
    "& 所以有\\frac{\\partial{E}}{\\partial{\\bf{W}}^{[2]}} = \n",
    "\\sum_{i=1}^{c}\n",
    "\\frac{{\\partial{\\bf{z}^{[2]}_{i}}}}{{\\partial{\\bf{W}^{[2]}}}}\n",
    "(p_{i}-y_{i}) = \n",
    "\\begin{bmatrix}\n",
    "(p_{1}-y_{1})h_{1} & (p_{1}-y_{1})h_{2}& \\cdots &(p_{1}-y_{1})h_{b} \\\\\n",
    "(p_{2}-y_{2})h_{1} & (p_{2}-y_{2})h_{2}& \\cdots &(p_{2}-y_{2})h_{b} \\\\\n",
    "\\vdots & \\vdots& \\ddots &\\vdots \\\\\n",
    "(p_{c}-y_{c})h_{1} & (p_{c}-y_{c})h_{2}& \\cdots &(p_{2}-y_{2})h_{b} \\\\\n",
    "\\end{bmatrix} \\in{R^{c \\times b}}\\\\\n",
    "&观察可发现又等于 : [\\bf{p}-\\bf{y}]^{T}h^{T}\\\\\n",
    "\\\\\n",
    "& \\frac{\\partial{E}}{\\partial{h}} = (\\bf{p}-\\bf{y} )\n",
    "\\frac{\\partial{\\bf{z}^{[2]}}}{\\partial{h}}\n",
    "=  (\\bf{p}-\\bf{y} )^{T}\\bf{W^{[2]}} \\\\\n",
    "& \\frac{\\partial{E}}{\\partial{b}^{[1]}} = \\frac{\\partial{E}}{\\partial{h}} \n",
    "\\frac{\\partial{h}}{\\partial{z{^{[1]}}}} \\frac{\\partial{z{^{[1]}}}}{\\bf{b^{[1]}}}=\n",
    "[(\\bf{p}-\\bf{y} )^{T}\\bf{W^{[2]}}\\circ sigmoid^{'}(z^{[1]})]^{T}\\\\\n",
    "& \\frac{\\partial{E}}{\\partial{w}^{[1]}} = \\frac{\\partial{E}}{\\partial{h}} \n",
    "\\frac{\\partial{h}}{\\partial{z{^{[1]}}}} \\frac{\\partial{z{^{[1]}}}}{\\bf{W^{[1]}}}=\n",
    "[(\\bf{p}-\\bf{y} )^{T}\\bf{W^{[2]}} \\circ sigmoid^{'}(z^{[1]})]^{T}x^{T}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    with open('../data/mnist_train.csv', 'r') as f:\n",
    "        data = [x.strip().split(',') for x in f]\n",
    "        data = np.asarray(data, dtype='float').T\n",
    "        # print(data[0][:10])\n",
    "        y = np.zeros((10, len(data[0])))\n",
    "        for i, x in enumerate(data[0]):\n",
    "            y[:, i][int(x)] = 1\n",
    "        x = np.delete(data, 0, 0)\n",
    "        x = (x / 255.0 * 0.99) + 0.01\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def get_test_data():\n",
    "    with open('../data/mnist_test.csv', 'r') as f:\n",
    "        data = [x.strip().split(',') for x in f]\n",
    "        data = np.asarray(data, dtype='float').T\n",
    "        # print(data[0][:10])\n",
    "        y = data[0]\n",
    "        x = np.delete(data, 0, 0)\n",
    "        x = (x / 255.0 * 0.99) + 0.01\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# 激活函数\n",
    "def sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "\n",
    "# def softmax(x):\n",
    "#     # RuntimeWarning: overflow encountered in exp\n",
    "#     x = np.exp(x)\n",
    "#     return x / np.sum(x)\n",
    "def softmax(x):\n",
    "    if x.shape[1] == 1:\n",
    "        exp = np.exp(x - np.max(x))\n",
    "        return exp / np.sum(exp)\n",
    "    else:\n",
    "        exp = np.exp(x-np.max(x, axis=0, keepdims=True))\n",
    "        return exp / np.sum(exp, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "\n",
    "def derivative_of_relu(x):\n",
    "    x[x <= 0] = 0\n",
    "    x[x > 0] = 1\n",
    "    return x\n",
    "\n",
    "\n",
    "def cross_entropy(predictions, targets, epsilon=1e-12):\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[1]\n",
    "    ce = -np.sum(targets*np.log(predictions))/N\n",
    "    return ce\n",
    "\n",
    "\n",
    "class SimpleNetwork:\n",
    "    def __init__(self,learning_rate, input_node, hidden_node, output_node, hidden_activation_function, output_activation_function):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.input_node = input_node\n",
    "        self.w1 = np.random.randn(hidden_node, input_node)*0.01\n",
    "        # self.w1 = np.random.normal(0.0, pow(hidden_node, -0.5), (hidden_node, input_node))\n",
    "        self.b1 = np.zeros((hidden_node, 1))\n",
    "        self.w2 = np.random.randn(output_node, hidden_node)*0.01\n",
    "        # self.w2 = np.random.normal(0.0, pow(output_node, -0.5), (output_node, hidden_node))\n",
    "        self.b2 = np.zeros((output_node, 1))\n",
    "        self.hidden_activation_function = hidden_activation_function\n",
    "        self.output_activation_function = output_activation_function\n",
    "\n",
    "    def train_vectorization(self, samples, marks):\n",
    "        size_of_samples = samples.shape[1]\n",
    "\n",
    "        z1 = np.dot(self.w1, samples) + self.b1\n",
    "        h = self.hidden_activation_function(z1)\n",
    "        z2 = np.dot(self.w2, h) + self.b2\n",
    "        p = self.output_activation_function(z2)\n",
    "        print('error', cross_entropy(p, marks))\n",
    "\n",
    "        dz2 = (p-marks).T / size_of_samples\n",
    "        dw2 = np.dot(dz2.T, h.T)\n",
    "        db2 = np.sum(dz2.T, axis=1, keepdims=True)\n",
    "\n",
    "        dz1 = np.dot(dz2, self.w2).T * derivative_of_relu(z1)\n",
    "        db1 = np.sum(dz1, axis=1, keepdims=True)\n",
    "        dw1 = np.dot(dz1, x.T)\n",
    "\n",
    "        # check dimensionality\n",
    "        # print('dw2', dw2.shape, self.w2.shape)\n",
    "        # print('db2', db2.shape, self.b2.shape)\n",
    "        # print('db1', db1.shape, self.b1.shape)\n",
    "        # print('dw1',dw1.shape,self.w1.shape)\n",
    "\n",
    "        self.w1 = self.w1 - self.learning_rate*dw1\n",
    "        self.b1 = self.b1 - self.learning_rate*db1\n",
    "        self.w2 = self.w2 - self.learning_rate*dw2\n",
    "        self.b2 = self.b2 - self.learning_rate*db2\n",
    "\n",
    "    def train_single(self, samples, marks):\n",
    "        for data in zip(samples.T,marks.T):\n",
    "            x = data[0].reshape((data[0].shape[0],1))\n",
    "            y = data[1].reshape((data[1].shape[0],1))\n",
    "\n",
    "            z1 = np.dot(self.w1, x) + self.b1\n",
    "            h = self.hidden_activation_function(z1)\n",
    "            z2 = np.dot(self.w2, h) + self.b2\n",
    "            p = self.output_activation_function(z2)\n",
    "            # print('error', cross_entropy(p, y))\n",
    "\n",
    "            dw2 = np.dot((p - y), h.T)\n",
    "            db2 = p - y\n",
    "            dz1 = np.dot((p - y).T, self.w2).T * derivative_of_relu(z1)\n",
    "            db1 = dz1\n",
    "            dw1 = np.dot(dz1, x.T)\n",
    "\n",
    "            self.w1 = self.w1 - self.learning_rate * dw1\n",
    "            self.b1 = self.b1 - self.learning_rate * db1\n",
    "            self.w2 = self.w2 - self.learning_rate * dw2\n",
    "            self.b2 = self.b2 - self.learning_rate * db2\n",
    "\n",
    "    def predict(self, features):\n",
    "        features = features.reshape((self.input_node,1))\n",
    "\n",
    "        z1 = np.dot(self.w1, features) + self.b1\n",
    "        h = self.hidden_activation_function(z1)\n",
    "        z2 = np.dot(self.w2, h) + self.b2\n",
    "        p = self.output_activation_function(z2)\n",
    "\n",
    "        p = p.tolist()\n",
    "        return p.index(max(p))\n",
    "\n",
    "    def test(self, samples, marks):\n",
    "        false = 0\n",
    "        for i in zip(samples.T, marks):\n",
    "            predict_number = self.predict(i[0])\n",
    "            if predict_number != i[1]:\n",
    "                false += 1\n",
    "        print('ratio____________________  ',(10000-false)/100)\n",
    "\n",
    "\n",
    "x, y = get_data()\n",
    "x_t, y_t = get_test_data()\n",
    "nw = SimpleNetwork(0.2, 784, 300, 10, relu, softmax)\n",
    "s = time.time()\n",
    "print('start')\n",
    "# 多样本单次训练\n",
    "for i in range(1000):\n",
    "    # print(i)\n",
    "    nw.train_vectorization(x, y)\n",
    "    nw.test(x_t, y_t)\n",
    "\n",
    "\n",
    "# 单样本多次训练\n",
    "# for i in range(100):\n",
    "#     nw.train_single(x, y)\n",
    "#     nw.test(x_t, y_t)\n",
    "\n",
    "print('time',time.time()-s)\n",
    "nw.test(x_t,y_t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
